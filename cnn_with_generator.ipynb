{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.get_from_mongo import get_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_from_char = {\n",
    "    'CAPTAIN_FALCON' : 1 ,\n",
    "    'DONKEY_KONG'    : 2 ,\n",
    "    'FOX'            : 3 ,\n",
    "    'GAME_AND_WATCH' : 4 ,\n",
    "    'KIRBY'          : 5 ,\n",
    "    'BOWSER'         : 6 ,\n",
    "    'LINK'           : 7 ,\n",
    "    'LUIGI'          : 8 ,\n",
    "    'MARIO'          : 9 ,\n",
    "    'MARTH'          : 10 ,\n",
    "    'MEWTWO'         : 11 ,\n",
    "    'NESS'           : 12 ,\n",
    "    'PEACH'          : 13 ,\n",
    "    'PIKACHU'        : 14 ,\n",
    "    'ICE_CLIMBERS'   : 15 ,\n",
    "    'JIGGLYPUFF'     : 16 ,\n",
    "    'SAMUS'          : 17 ,\n",
    "    'YOSHI'          : 18 ,\n",
    "    'ZELDA'          : 19 ,\n",
    "    'SHEIK'          : 20 ,\n",
    "    'FALCO'          : 21 ,\n",
    "    'YOUNG_LINK'     : 22 ,\n",
    "    'DR_MARIO'       : 23 ,\n",
    "    'ROY'            : 24 ,\n",
    "    'PICHU'          : 25 ,\n",
    "    'GANONDORF'      : 26 ,\n",
    "}\n",
    "\n",
    "char_from_id = {v:k for k, v in id_from_char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'slippi'\n",
    "collection_name = 'melee_clips_30s'\n",
    "\n",
    "# Connect to the hosted MongoDB instance\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client[database_name]\n",
    "collection = db[collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(clip_collection=collection, # collection containing clips\n",
    "                   batch_size = 100\n",
    "):\n",
    "#     I_ = np.random.permutation(I)\n",
    "#     i = 0\n",
    "#     while i < len(I_):\n",
    "#         try:\n",
    "#             query = {'$or':[\n",
    "#                 {'clip_id':int(clip_id)} for clip_id in I_[i:i+batch_size]\n",
    "#             ]}\n",
    "#         except IndexError:\n",
    "#             query = {'$or':[\n",
    "#                 {'clip_id':int(clip_id)} for clip_id in I_[i:]\n",
    "#             ]}\n",
    "        cur = clip_collection.find()\n",
    "            \n",
    "        while cur.alive:\n",
    "            \n",
    "            xi = []\n",
    "            yi = []\n",
    "            \n",
    "            for _ in range(batch_size):\n",
    "                clip = next(cur)\n",
    "                xi.append(pickle.loads(clip['istream']).toarray())\n",
    "                yi.append(id_from_char[clip['character']])\n",
    "\n",
    "            Xi = np.stack(xi, axis=0)\n",
    "            Yi = tf.one_hot(yi, 26)\n",
    "\n",
    "            yield Xi, Yi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(clip_collection=collection, # collection containing clips\n",
    "                  size = 100\n",
    "):\n",
    "    bytestreams, characters = get_data('slippi', \n",
    "                                       'melee_public_slp_dataset',\n",
    "                                       get=6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen = data_generator(I_train, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xi, Yi = next(gen)\n",
    "# for Y in Yi:\n",
    "#     print(char_from_id[np.argmax(Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, InputLayer\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first conv layer\n",
    "model.add(Conv1D(100, #num of features extracted from istream\n",
    "                 60, #number of frames filter can see at once\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(Conv1D(80,\n",
    "                 30,\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(Conv1D(60,\n",
    "                 15,\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(40, activation='relu'))\n",
    "\n",
    "# final output layer\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "                \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 915730\n"
     ]
    }
   ],
   "source": [
    "# Get ids for train and test datasets\n",
    "N = collection.estimated_document_count()\n",
    "# because it's an estimate, fudge it down to avoid accidental index errors\n",
    "N = int(N * .999)\n",
    "print(f'N = {N}')\n",
    "I_train, I_test = train_test_split(np.arange(N), test_size=.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_generator(batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 513s 1s/step - loss: 13.3641 - accuracy: 0.3613\n",
      "\n",
      "Test score: 3.45\n",
      "Test accuracy: 23%\n"
     ]
    }
   ],
   "source": [
    "# during fit process watch train and test error simultaneously\n",
    "model.fit(data, epochs=1, steps_per_epoch=500, verbose=1)\n",
    "\n",
    "score = model.evaluate(data, steps=10, verbose=0)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')  # this is the one we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_matrix(labels_as_id, predictions_as_id):\n",
    "    conf_matrix = np.zeros((27,27))\n",
    "    for i_real, i_pred in zip(labels_as_id, predictions_as_id):\n",
    "        conf_matrix[i_real, i_pred] += 1\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(model.predict(X_test), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = get_conf_matrix(y_test, pred)\n",
    "char_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_id += 1\n",
    "row = conf_matrix[char_id, :]\n",
    "sorted_row_indices = np.argsort(row)[::-1]\n",
    "print(f'{char_from_id[char_id]} : prediction frequencies\\n-----------------')\n",
    "for i in sorted_row_indices:\n",
    "    if i > 0:\n",
    "        print(f'{char_from_id[i]} : {row[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(i, ii):\n",
    "    character = characters[i]\n",
    "    istream = pickle.loads(bytestreams[i])\n",
    "\n",
    "    y_test = []\n",
    "    x_test = []\n",
    "    f=0\n",
    "\n",
    "    while f+F < istream.shape[0]:\n",
    "        y_test.append(id_from_char[character])\n",
    "        x_test.append(istream[f:f+F])\n",
    "        f += F\n",
    "        \n",
    "    try:\n",
    "        d = x_test[ii].toarray()\n",
    "    except IndexError:\n",
    "        test(i, ii-1)\n",
    "        return\n",
    "    \n",
    "    pred = char_from_id[np.argmax(model.predict(d.reshape(1,d.shape[0],d.shape[1])))]\n",
    "\n",
    "\n",
    "    print(f'''\n",
    "    Actual Character:\n",
    "    ---------------\n",
    "    {char_from_id[y_test[ii]]}\n",
    "    ''')\n",
    "\n",
    "    print(f'''\n",
    "    Detected Character:\n",
    "    ---------------\n",
    "    {pred}\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 602 # use this to check different entries\n",
    "i = 630 # use this to check different entries\n",
    "ii = 3 # use this to look at different clips from that entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(characters[i], '\\n', f'i={i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(i, ii)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
