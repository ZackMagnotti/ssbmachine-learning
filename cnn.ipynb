{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from src.get_from_mongo import get_data\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_from_char = {\n",
    "    'CAPTAIN_FALCON' : 1 ,\n",
    "    'DONKEY_KONG'    : 2 ,\n",
    "    'FOX'            : 3 ,\n",
    "    'GAME_AND_WATCH' : 4 ,\n",
    "    'KIRBY'          : 5 ,\n",
    "    'BOWSER'         : 6 ,\n",
    "    'LINK'           : 7 ,\n",
    "    'LUIGI'          : 8 ,\n",
    "    'MARIO'          : 9 ,\n",
    "    'MARTH'          : 10 ,\n",
    "    'MEWTWO'         : 11 ,\n",
    "    'NESS'           : 12 ,\n",
    "    'PEACH'          : 13 ,\n",
    "    'PIKACHU'        : 14 ,\n",
    "    'ICE_CLIMBERS'   : 15 ,\n",
    "    'JIGGLYPUFF'     : 16 ,\n",
    "    'SAMUS'          : 17 ,\n",
    "    'YOSHI'          : 18 ,\n",
    "    'ZELDA'          : 19 ,\n",
    "    'SHEIK'          : 20 ,\n",
    "    'FALCO'          : 21 ,\n",
    "    'YOUNG_LINK'     : 22 ,\n",
    "    'DR_MARIO'       : 23 ,\n",
    "    'ROY'            : 24 ,\n",
    "    'PICHU'          : 25 ,\n",
    "    'GANONDORF'      : 26 ,\n",
    "}\n",
    "\n",
    "char_from_id = {v:k for k, v in id_from_char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'slippi'\n",
    "collection_name = 'Blynde'\n",
    "\n",
    "# Connect to the hosted MongoDB instance\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client[database_name]\n",
    "collection = db[collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents retrieved: 1816\n"
     ]
    }
   ],
   "source": [
    "bytestreams, characters = get_data(database_name, collection_name)\n",
    "print(f'Documents retrieved: {len(characters)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "x = []\n",
    "y = []\n",
    "for bytestream, character in zip(bytestreams, characters):\n",
    "    istream = pickle.loads(bytestream).toarray()\n",
    "    T = 15     # clip length in seconds\n",
    "    F = T * 60 # clip length in frames\n",
    "    f = 0      # clip starting frame\n",
    "    while f+F < istream.shape[0]:\n",
    "        y.append(id_from_char[character])\n",
    "        x.append(istream[f:f+F])\n",
    "        f += F\n",
    "\n",
    "X = np.stack(x, axis=0)\n",
    "Y = tf.one_hot(y, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = X[:-500], Y[:-500]\n",
    "X_test, Y_test = X[-500:], Y[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first conv layer\n",
    "model.add(Conv1D(, #num of features extracted from istream\n",
    "                 60, #number of frames filter can see at once\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(100,\n",
    "                 ,\n",
    "                 activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(40, activation='relu'))\n",
    "\n",
    "# final output layer\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "                \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# during fit process watch train and test error simultaneously\n",
    "model.fit(X_train, Y_train, batch_size=100, epochs=2,\n",
    "          verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print(f'Test accuracy: {round(score[1]*100)}')  # this is the one we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = 15*60\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytestreams, characters = get_data('slippi', 'gh0st')\n",
    "print(f'Documents retrieved: {len(characters)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "x = []\n",
    "y = []\n",
    "for bytestream, character in zip(bytestreams, characters):\n",
    "    istream = pickle.loads(bytestream).toarray()\n",
    "    T = 15     # clip length in seconds\n",
    "    F = T * 60 # clip length in frames\n",
    "    f = 0      # clip starting frame\n",
    "    while f+F < istream.shape[0]:\n",
    "        y.append(get_char_id[character])\n",
    "        x.append(istream[f:f+F])\n",
    "        f += F\n",
    "        \n",
    "\n",
    "X_ramon = np.stack(x, axis=0)\n",
    "Y_ramon = tf.one_hot(y, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 200\n",
    "character = characters[i]\n",
    "istream = pickle.loads(bytestreams[i])\n",
    "character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ramon = []\n",
    "x_ramon = []\n",
    "f=0\n",
    "\n",
    "while f+F < istream.shape[0]:\n",
    "    y_ramon.append(get_char_id[character])\n",
    "    x_ramon.append(istream[f:f+F])\n",
    "    f += F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 4\n",
    "char_from_id[y_ramon[ii]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = x_ramon[ii].toarray()\n",
    "char_from_id[np.argmax(model.predict(d.reshape(1,d.shape[0],d.shape[1])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
