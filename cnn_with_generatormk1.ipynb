{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.get_from_mongo import get_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymongo import MongoClient\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_from_char = {\n",
    "    'CAPTAIN_FALCON' : 1 ,\n",
    "    'DONKEY_KONG'    : 2 ,\n",
    "    'FOX'            : 3 ,\n",
    "    'GAME_AND_WATCH' : 4 ,\n",
    "    'KIRBY'          : 5 ,\n",
    "    'BOWSER'         : 6 ,\n",
    "    'LINK'           : 7 ,\n",
    "    'LUIGI'          : 8 ,\n",
    "    'MARIO'          : 9 ,\n",
    "    'MARTH'          : 10 ,\n",
    "    'MEWTWO'         : 11 ,\n",
    "    'NESS'           : 12 ,\n",
    "    'PEACH'          : 13 ,\n",
    "    'PIKACHU'        : 14 ,\n",
    "    'ICE_CLIMBERS'   : 15 ,\n",
    "    'JIGGLYPUFF'     : 16 ,\n",
    "    'SAMUS'          : 17 ,\n",
    "    'YOSHI'          : 18 ,\n",
    "    'ZELDA'          : 19 ,\n",
    "    'SHEIK'          : 20 ,\n",
    "    'FALCO'          : 21 ,\n",
    "    'YOUNG_LINK'     : 22 ,\n",
    "    'DR_MARIO'       : 23 ,\n",
    "    'ROY'            : 24 ,\n",
    "    'PICHU'          : 25 ,\n",
    "    'GANONDORF'      : 26 ,\n",
    "}\n",
    "\n",
    "char_from_id = {v:k for k, v in id_from_char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = 'slippi'\n",
    "collection_name = 'melee_clips_30s'\n",
    "\n",
    "# Connect to the hosted MongoDB instance\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client[database_name]\n",
    "collection = db[collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(clip_collection=collection, # collection containing clips\n",
    "                   batch_size = 100,\n",
    "                   skip=None,\n",
    "                   step=1,\n",
    "                   repeat=False,\n",
    "                   repeat_offset=0):\n",
    "\n",
    "        cur = clip_collection.find()\n",
    "        \n",
    "        if skip:\n",
    "            cur.skip(skip)\n",
    "            \n",
    "        while cur.alive:\n",
    "            \n",
    "            xi = []\n",
    "            yi = []\n",
    "            \n",
    "            for _ in range(batch_size):\n",
    "                \n",
    "                for _ in range(step):\n",
    "                    \n",
    "                    try:\n",
    "                        clip = next(cur)\n",
    "                        \n",
    "                    except StopIteration:\n",
    "                        if repeat:\n",
    "                            skip += repeat_offset\n",
    "                            cur = clip_collection.find()\n",
    "                            cur.skip(skip)\n",
    "                            clip = next(cur)\n",
    "                        else:\n",
    "                            raise\n",
    "                            \n",
    "                xi.append(pickle.loads(clip['istream']).toarray())\n",
    "                yi.append(id_from_char[clip['character']])\n",
    "\n",
    "            Xi = np.stack(xi, axis=0)\n",
    "            Yi = tf.one_hot(yi, 26)\n",
    "\n",
    "            yield Xi, Yi\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, InputLayer\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "top_8_accuracy = keras.metrics.TopKCategoricalAccuracy(k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first conv layer\n",
    "model.add(Conv1D(100, #num of features extracted from istream\n",
    "                 30, #number of frames filter can see at once\n",
    "                 activation='tanh'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(80,\n",
    "                 30,\n",
    "                 activation='elu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Conv1D(80,\n",
    "                 30,\n",
    "                 activation='elu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=10))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(80, activation='elu'))\n",
    "\n",
    "model.add(Dense(40, activation='elu'))\n",
    "\n",
    "# final output layer\n",
    "model.add(Dense(26, activation='softmax'))\n",
    "                \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', 'categorical_accuracy', top_8_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_generator(batch_size=100, skip=100000, step=5, repeat=True, repeat_offset=1) # keep first 100000 clips as test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "500/500 [==============================] - 840s 2s/step - loss: 1.3521 - accuracy: 0.5849 - categorical_accuracy: 0.5849 - top_k_categorical_accuracy: 0.9152\n",
      "Epoch 2/2\n",
      "500/500 [==============================] - 847s 2s/step - loss: 0.8542 - accuracy: 0.7499 - categorical_accuracy: 0.7499 - top_k_categorical_accuracy: 0.9433\n",
      "\n",
      "Test score: 0.717\n",
      "Test accuracy: 79%\n",
      "Test categorical accuracy: 79%\n",
      "Test test top 8 categorical accuracy: 79%\n"
     ]
    }
   ],
   "source": [
    "# during fit process watch train and test error simultaneously\n",
    "model.fit(data, epochs=2, steps_per_epoch=500, verbose=1)\n",
    "\n",
    "score = model.evaluate(data, steps=50, verbose=0)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test categorical accuracy: {round(score[2]*100)}%')\n",
    "print(f'Test test top 8 categorical accuracy: {round(score[3]*100)}%')  # this is the one we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_matrix(labels_as_id, predictions_as_id):\n",
    "    conf_matrix = np.zeros((27,27))\n",
    "    for i_real, i_pred in zip(labels_as_id, predictions_as_id):\n",
    "        conf_matrix[i_real, i_pred] += 1\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = next(data_generator(batch_size=5000, step = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(model.predict(X_test), axis = 1)\n",
    "y_test = np.argmax(Y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test score: 0.706\n",
      "Test accuracy: 79%\n",
      "Test test top 8 categorical accuracy: 96%\n"
     ]
    }
   ],
   "source": [
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test test top 8 categorical accuracy: {round(score[3]*100)}%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = {k:0 for k in range(1,27)}\n",
    "precisions = {k:0 for k in range(1,27)}\n",
    "conf_matrix = get_conf_matrix(y_test, pred)\n",
    "char_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPTAIN_FALCON\n",
      "Recall: 79.8%\n",
      " ------------------\n",
      "CAPTAIN_FALCON : 479.0\n",
      "MARTH : 57.0\n",
      "SHEIK : 33.0\n",
      "FOX : 19.0\n",
      "JIGGLYPUFF : 4.0\n",
      "FALCO : 3.0\n",
      "ICE_CLIMBERS : 2.0\n",
      "PEACH : 1.0\n",
      "YOSHI : 1.0\n",
      "LUIGI : 1.0\n",
      "DONKEY_KONG : 0.0\n",
      "GAME_AND_WATCH : 0.0\n",
      "KIRBY : 0.0\n",
      "BOWSER : 0.0\n",
      "LINK : 0.0\n",
      "MARIO : 0.0\n",
      "GANONDORF : 0.0\n",
      "MEWTWO : 0.0\n",
      "NESS : 0.0\n",
      "PICHU : 0.0\n",
      "PIKACHU : 0.0\n",
      "SAMUS : 0.0\n",
      "ZELDA : 0.0\n",
      "YOUNG_LINK : 0.0\n",
      "DR_MARIO : 0.0\n",
      "ROY : 0.0\n"
     ]
    }
   ],
   "source": [
    "char_id += 1\n",
    "row = conf_matrix[char_id, :]\n",
    "sorted_row_indices = np.argsort(row)[::-1]\n",
    "correct = conf_matrix[char_id, char_id]\n",
    "total = np.sum(row)\n",
    "recall = correct/total if total else 0\n",
    "recalls[char_id] = recall\n",
    "print(f'{char_from_id[char_id]}')\n",
    "print(f'Recall: {round(100*recall, 1)}%\\n ------------------')\n",
    "for i in sorted_row_indices:\n",
    "    if i > 0:\n",
    "        print(f'{char_from_id[i]} : {row[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHEIK:\t93.1%\n",
      "FALCO:\t92.8%\n",
      "FOX:\t91.3%\n",
      "PEACH:\t89.7%\n",
      "MARTH:\t86.2%\n",
      "CAPTAIN_FALCON:\t79.8%\n",
      "SAMUS:\t70.8%\n",
      "JIGGLYPUFF:\t63.5%\n",
      "YOSHI:\t33.3%\n",
      "ICE_CLIMBERS:\t27.6%\n",
      "PIKACHU:\t23.1%\n",
      "LINK:\t8.3%\n",
      "DR_MARIO:\t4.0%\n",
      "LUIGI:\t1.9%\n",
      "DONKEY_KONG:\t0.0%\n",
      "GAME_AND_WATCH:\t0.0%\n",
      "KIRBY:\t0.0%\n",
      "BOWSER:\t0.0%\n",
      "MARIO:\t0.0%\n",
      "MEWTWO:\t0.0%\n",
      "NESS:\t0.0%\n",
      "ZELDA:\t0.0%\n",
      "YOUNG_LINK:\t0.0%\n",
      "ROY:\t0.0%\n",
      "PICHU:\t0.0%\n",
      "GANONDORF:\t0%\n"
     ]
    }
   ],
   "source": [
    "for i, acc in {k: v for k, v in sorted(recalls.items(), key=lambda item: -item[1])}.items():\n",
    "    print(f'{char_from_id[i]}:\\t{round(100*acc, 1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPTAIN_FALCON\n",
      "Precision: 78.9%\n",
      " ------------------\n",
      "CAPTAIN_FALCON : 479.0\n",
      "MARTH : 21.0\n",
      "FOX : 17.0\n",
      "DONKEY_KONG : 11.0\n",
      "PIKACHU : 10.0\n",
      "PEACH : 7.0\n",
      "FALCO : 7.0\n",
      "YOSHI : 6.0\n",
      "JIGGLYPUFF : 4.0\n",
      "ICE_CLIMBERS : 3.0\n",
      "DR_MARIO : 3.0\n",
      "ZELDA : 2.0\n",
      "MEWTWO : 2.0\n",
      "ROY : 2.0\n",
      "MARIO : 2.0\n",
      "NESS : 2.0\n",
      "SHEIK : 2.0\n",
      "SAMUS : 2.0\n",
      "LUIGI : 1.0\n",
      "KIRBY : 1.0\n",
      "GAME_AND_WATCH : 1.0\n",
      "PICHU : 0.0\n",
      "LINK : 0.0\n",
      "BOWSER : 0.0\n",
      "YOUNG_LINK : 0.0\n",
      "GANONDORF : 0.0\n"
     ]
    }
   ],
   "source": [
    "char_id += 1\n",
    "col = conf_matrix[:, char_id]\n",
    "sorted_col_indices = np.argsort(col)[::-1]\n",
    "correct = conf_matrix[char_id, char_id]\n",
    "total = np.sum(col)\n",
    "precision = correct/total if total else 0\n",
    "precisions[char_id] = precision\n",
    "print(f'{char_from_id[char_id]}')\n",
    "print(f'Precision: {round(100*precision, 1)}%\\n ------------------')\n",
    "for i in sorted_col_indices:\n",
    "    if i > 0:\n",
    "        print(f'{char_from_id[i]} : {col[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIKACHU:\t93.8%\n",
      "PEACH:\t92.9%\n",
      "FALCO:\t92.3%\n",
      "FOX:\t91.7%\n",
      "YOSHI:\t88.0%\n",
      "JIGGLYPUFF:\t79.8%\n",
      "CAPTAIN_FALCON:\t78.9%\n",
      "MARTH:\t68.3%\n",
      "ICE_CLIMBERS:\t62.8%\n",
      "SAMUS:\t61.4%\n",
      "SHEIK:\t49.8%\n",
      "LINK:\t40.0%\n",
      "DR_MARIO:\t33.3%\n",
      "LUIGI:\t10.0%\n",
      "DONKEY_KONG:\t0.0%\n",
      "GAME_AND_WATCH:\t0%\n",
      "KIRBY:\t0%\n",
      "BOWSER:\t0%\n",
      "MARIO:\t0%\n",
      "MEWTWO:\t0%\n",
      "NESS:\t0.0%\n",
      "ZELDA:\t0%\n",
      "YOUNG_LINK:\t0.0%\n",
      "ROY:\t0%\n",
      "PICHU:\t0%\n",
      "GANONDORF:\t0%\n"
     ]
    }
   ],
   "source": [
    "for i, acc in {k: v for k, v in sorted(precisions.items(), key=lambda item: -item[1])}.items():\n",
    "    print(f'{char_from_id[i]}:\\t{round(100*acc, 1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, None, 100)         39100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 80)          240080    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 80)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 80)          192080    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 80)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, None)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 80)                249680    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 40)                3240      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                1066      \n",
      "=================================================================\n",
      "Total params: 725,246\n",
      "Trainable params: 725,246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
