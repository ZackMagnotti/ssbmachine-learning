{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import player_data\n",
    "from src.util import characters, display_progress\n",
    "from src.transfer import replace_head\n",
    "from tensorflow import keras\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy as Focal\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# visualization\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Pre-Trained Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = keras.models.load_model('models/SSBML-Base-Model')\n",
    "\n",
    "# replace head\n",
    "model = replace_head(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many clips does a player have?\n",
    "!ls data/player/Blynde/train | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Player Data\n",
    "\n",
    "Player Data can be found in data/player/\\<player name\\>\n",
    "\n",
    "Nonplayer Data is taken from the large dataset data/character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the player we want to train/test on\n",
    "player_name = 'Blynde'\n",
    "\n",
    "player_dir = os.path.join('data/player', player_name)\n",
    "player_train_dir = os.path.join(player_dir, 'train')\n",
    "player_test_dir = os.path.join(player_dir, 'test')\n",
    "\n",
    "nonplayer_dir = 'data/character'\n",
    "nonplayer_train_dir = os.path.join(nonplayer_dir, 'train')\n",
    "nonplayer_test_dir = os.path.join(nonplayer_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training Data Located at: \\n\\t- {player_train_dir} \\n\\t- {nonplayer_train_dir} \\n')\n",
    "print(f'Testing Data Located at: \\n\\t- {player_test_dir} \\n\\t- {nonplayer_test_dir} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing data\n",
    "data_test_one_round = player_data(\n",
    "    player_test_dir,\n",
    "    nonplayer_test_dir,\n",
    "    batch_size = 32,\n",
    "    repeat = False,\n",
    "    ratio = 1,\n",
    "    onehot = True\n",
    ")\n",
    "\n",
    "score = model.evaluate(data_test_one_round, verbose=1)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test precision: {round(score[2]*100)}%')\n",
    "print(f'Test recall: {round(score[3]*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_conf = player_data(\n",
    "    player_test_dir,\n",
    "    nonplayer_test_dir,\n",
    "    batch_size = 10,\n",
    "    repeat = False,\n",
    "    onehot = True\n",
    "#     ratio=.1,\n",
    ")\n",
    "\n",
    "batch_preds = []\n",
    "batch_labels = []\n",
    "i = 0\n",
    "\n",
    "for xi, yi in data_conf:\n",
    "    batch_preds.append(np.argmax(model.predict(xi), axis=1))#.astype(int).reshape((-1)))\n",
    "    batch_labels.append(np.argmax(yi, axis=1))\n",
    "    \n",
    "    # just in case\n",
    "    i += 1\n",
    "    if i > 50000:\n",
    "        break\n",
    "    \n",
    "#     i+=1\n",
    "#     display_progress(i, num_batches)\n",
    "# display_progress(num_batches, num_batches)\n",
    "    \n",
    "pred = np.concatenate(batch_preds)\n",
    "labels = np.concatenate(batch_labels)\n",
    "\n",
    "conf_matrix = confusion_matrix(labels, pred, normalize='all') # reverse so true positive is top left, true negative is bottom right\n",
    "conf_matrix = np.around(conf_matrix, 3)\n",
    "conf_df = pd.DataFrame(conf_matrix, index=['present', 'not present'], columns=['detected', 'not detected'])\n",
    "\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# training data\n",
    "imbalanced_data = player_data(\n",
    "    player_train_dir,\n",
    "    nonplayer_train_dir,\n",
    "    repeat = True,\n",
    "    batch_size = batch_size,\n",
    "    ratio=1/10,\n",
    ")\n",
    "\n",
    "# training data\n",
    "balanced_data = player_data(\n",
    "    player_train_dir,\n",
    "    nonplayer_train_dir,\n",
    "    repeat = True,\n",
    "    batch_size = batch_size,\n",
    "    ratio=1,\n",
    ")\n",
    "\n",
    "# testing data\n",
    "balanced_test_data = player_data(\n",
    "    player_test_dir,\n",
    "    nonplayer_test_dir,\n",
    "    repeat = True,\n",
    "    batch_size = batch_size,\n",
    "    ratio=1,\n",
    ")\n",
    "\n",
    "imbalanced_test_data = player_data(\n",
    "    player_test_dir,\n",
    "    nonplayer_test_dir,\n",
    "    repeat = True,\n",
    "    batch_size = batch_size,\n",
    "    ratio=1/10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on imbalance classes first\n",
    "model.fit(\n",
    "    imbalanced_data,\n",
    "    epochs = 2,\n",
    "    steps_per_epoch = 4000,\n",
    "    verbose = 1,\n",
    ")\n",
    "# then train on balanced classes\n",
    "model.fit(\n",
    "    balanced_data,\n",
    "    epochs = 2,\n",
    "    steps_per_epoch = 400,\n",
    "    verbose = 1,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanced Classes\n",
    "score = model.evaluate(balanced_test_data, verbose=0, steps=40)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test precision: {round(score[2]*100)}%')\n",
    "print(f'Test recall: {round(score[3]*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalance Classes\n",
    "score = model.evaluate(imbalanced_test_data, verbose=0, steps=40)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test precision: {round(score[2]*100)}%')\n",
    "print(f'Test recall: {round(score[3]*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze layers\n",
    "\n",
    "# reduce learning rate\n",
    "optimizer = keras.optimizers.Adam(\n",
    "    learning_rate = .00005,\n",
    ")\n",
    "# compile\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "model.fit(\n",
    "    imbalanced_data,\n",
    "    epochs = 5,\n",
    "    steps_per_epoch = 4000,\n",
    "    verbose = 1,\n",
    ")\n",
    "\n",
    "score = model.evaluate(imbalanced_test_data, verbose=0, steps=400)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test precision: {round(score[2]*100)}%')\n",
    "print(f'Test recall: {round(score[3]*100)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
