{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import player_data\n",
    "from src.util import characters, display_progress\n",
    "from src.transfer import ssbml_transfer_model, onehot_head, onehot_metrics\n",
    "from tensorflow import keras\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy as Focal\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# visualization\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Pre-Trained Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-4_layer_call_and_return_conditional_losses_1283532) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_activation_2_layer_call_and_return_conditional_losses_1284374) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_4_layer_call_and_return_conditional_losses_1283891) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_activation_3_layer_call_and_return_conditional_losses_1284517) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_6_layer_call_and_return_conditional_losses_1284115) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_7_layer_call_and_return_conditional_losses_1280886) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-1_layer_call_and_return_conditional_losses_1283204) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_4_layer_call_and_return_conditional_losses_1280033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_7_layer_call_and_return_conditional_losses_1284254) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_6_layer_call_and_return_conditional_losses_1280683) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_5_layer_call_and_return_conditional_losses_1280358) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_5_layer_call_and_return_conditional_losses_1284003) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_DenseCell-2_layer_call_and_return_conditional_losses_1283816) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-2_layer_call_and_return_conditional_losses_1283336) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_DenseCell-2_layer_call_and_return_conditional_losses_1283783) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-3_layer_call_and_return_conditional_losses_1283477) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_DenseCell-1_layer_call_and_return_conditional_losses_1283693) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-4_layer_call_and_return_conditional_losses_1283553) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-3_layer_call_and_return_conditional_losses_1283435) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-1_layer_call_and_return_conditional_losses_1283163) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_DenseCell-1_layer_call_and_return_conditional_losses_1283660) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-2_layer_call_and_return_conditional_losses_1283295) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_activation_2_layer_call_and_return_conditional_losses_1281183) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_activation_3_layer_call_and_return_conditional_losses_1281532) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "model = ssbml_transfer_model(\n",
    "    head = onehot_head, \n",
    "    loss = Focal(),\n",
    "    metrics = onehot_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SSBML-Transfer-Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "SSBML-Base-Model (Sequential (None, 512)               6537842   \n",
      "_________________________________________________________________\n",
      "onehot_binary_classifier (Se (None, 2)                 83458     \n",
      "=================================================================\n",
      "Total params: 6,621,300\n",
      "Trainable params: 82,946\n",
      "Non-trainable params: 6,538,354\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blynde\tCuckDaddy  Lie0x  TCBL\tgh0st  ixwonkr\n"
     ]
    }
   ],
   "source": [
    "!ls data/player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11758\n"
     ]
    }
   ],
   "source": [
    "# how many clips does a player have?\n",
    "!ls data/player/CuckDaddy/train | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Player Data\n",
    "\n",
    "Player Data can be found in data/player/\\<player name\\>\n",
    "\n",
    "Nonplayer Data is taken from the large dataset data/character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the player we want to train/test on\n",
    "player_name = 'CuckDaddy'\n",
    "\n",
    "player_dir = os.path.join('data/player', player_name)\n",
    "player_train_dir = os.path.join(player_dir, 'train')\n",
    "player_test_dir = os.path.join(player_dir, 'test')\n",
    "\n",
    "nonplayer_dir = 'data/character'\n",
    "nonplayer_train_dir = os.path.join(nonplayer_dir, 'train')\n",
    "nonplayer_test_dir = os.path.join(nonplayer_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Located at: \n",
      "\t- data/player/CuckDaddy/train \n",
      "\t- data/character/train \n",
      "\n",
      "Testing Data Located at: \n",
      "\t- data/player/CuckDaddy/test \n",
      "\t- data/character/test \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Data Located at: \\n\\t- {player_train_dir} \\n\\t- {nonplayer_train_dir} \\n')\n",
    "print(f'Testing Data Located at: \\n\\t- {player_test_dir} \\n\\t- {nonplayer_test_dir} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 3s 44ms/step - loss: 6.2158 - accuracy: 0.4675 - player_precision: 0.4948 - player_recall: 0.1086 - nonplayer_precision: 0.4639 - nonplayer_recall: 0.8744\n",
      "\n",
      "Test score: 6.216\n",
      "Test accuracy: 47%\n",
      "Test precision: 49%\n",
      "Test recall: 11%\n"
     ]
    }
   ],
   "source": [
    "# testing data\n",
    "data_test_one_round = player_data(\n",
    "    player_test_dir,\n",
    "    nonplayer_test_dir,\n",
    "    batch_size = 32,\n",
    "    repeat = False,\n",
    "    ratio = 1,\n",
    "    onehot = True\n",
    ")\n",
    "\n",
    "score = model.evaluate(data_test_one_round, verbose=1)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test precision: {round(score[2]*100)}%')\n",
    "print(f'Test recall: {round(score[3]*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted player</th>\n",
       "      <th>predicted nonplayer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true player</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true nonplayer</th>\n",
       "      <td>0.101</td>\n",
       "      <td>0.419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                predicted player  predicted nonplayer\n",
       "true player                0.048                0.432\n",
       "true nonplayer             0.101                0.419"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_conf = player_data(\n",
    "    player_test_dir,\n",
    "    nonplayer_test_dir,\n",
    "    batch_size = 25,\n",
    "    repeat = False,\n",
    "#     ratio=.1,\n",
    ")\n",
    "\n",
    "batch_preds = []\n",
    "batch_labels = []\n",
    "i = 0\n",
    "\n",
    "for xi, yi in data_conf:\n",
    "    batch_preds.append(np.around(model.predict(xi)).astype(int).reshape((-1)))\n",
    "    batch_labels.append(yi)\n",
    "    \n",
    "    # just in case\n",
    "    i += 1\n",
    "    if i > 50000:\n",
    "        break\n",
    "    \n",
    "#     i+=1\n",
    "#     display_progress(i, num_batches)\n",
    "# display_progress(num_batches, num_batches)\n",
    "    \n",
    "pred = np.concatenate(batch_preds)\n",
    "labels = np.concatenate(batch_labels)\n",
    "\n",
    "conf_matrix = confusion_matrix(labels, pred, normalize='all') # reverse so true positive is top left, true negative is bottom right\n",
    "conf_matrix = np.around(conf_matrix, 3)\n",
    "conf_df = pd.DataFrame(conf_matrix, index=['true player', 'true nonplayer'], columns=['predicted player', 'predicted nonplayer'])\n",
    "\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "onehot = True\n",
    "imbalanced_data = player_data(\n",
    "    player_train_dir,\n",
    "    nonplayer_train_dir,\n",
    "    repeat = True,\n",
    "    batch_size = 32,\n",
    "    ratio=1/10,\n",
    "    onehot = onehot,\n",
    ")\n",
    "\n",
    "# training data\n",
    "balanced_data = player_data(\n",
    "    player_train_dir,\n",
    "    nonplayer_train_dir,\n",
    "    repeat = True,\n",
    "    batch_size = 32,\n",
    "    ratio=1,\n",
    "    onehot = onehot,\n",
    ")\n",
    "\n",
    "# testing data\n",
    "balanced_test_data = player_data(\n",
    "    player_test_dir,\n",
    "    nonplayer_test_dir,\n",
    "    repeat = True,\n",
    "    batch_size = 25,\n",
    "    ratio=1,\n",
    "    onehot = onehot,\n",
    ")\n",
    "\n",
    "imbalanced_test_data = player_data(\n",
    "    player_test_dir,\n",
    "    nonplayer_test_dir,\n",
    "    repeat = True,\n",
    "    batch_size = 25,\n",
    "    ratio=1/10,\n",
    "    onehot = onehot,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "4000/4000 [==============================] - 178s 44ms/step - loss: 0.0430 - accuracy: 0.9509 - player_precision: 0.6584 - player_recall: 0.4456 - nonplayer_precision: 0.9638 - nonplayer_recall: 0.9846\n",
      "Epoch 2/2\n",
      "4000/4000 [==============================] - 178s 45ms/step - loss: 0.0322 - accuracy: 0.9609 - player_precision: 0.7957 - player_recall: 0.5033 - nonplayer_precision: 0.9677 - nonplayer_recall: 0.9914\n",
      "Epoch 1/2\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0967 - accuracy: 0.8429 - player_precision: 0.8574 - player_recall: 0.7975 - nonplayer_precision: 0.8317 - nonplayer_recall: 0.8829\n",
      "Epoch 2/2\n",
      "400/400 [==============================] - 18s 45ms/step - loss: 0.0777 - accuracy: 0.8655 - player_precision: 0.8623 - player_recall: 0.8487 - nonplayer_precision: 0.8683 - nonplayer_recall: 0.8804\n"
     ]
    }
   ],
   "source": [
    "# train on imbalance classes first\n",
    "model.fit(\n",
    "    imbalanced_data,\n",
    "    epochs = 2,\n",
    "    steps_per_epoch = 4000,\n",
    "    verbose = 1,\n",
    ")\n",
    "# then train on balanced classes\n",
    "model.fit(\n",
    "    balanced_data,\n",
    "    epochs = 2,\n",
    "    steps_per_epoch = 400,\n",
    "    verbose = 1,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test score: 0.072\n",
      "Test accuracy: 88%\n",
      "Test precision: 95%\n",
      "Test recall: 82%\n"
     ]
    }
   ],
   "source": [
    "# Balanced Classes\n",
    "score = model.evaluate(balanced_test_data, verbose=0, steps=40)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test precision: {round(score[2]*100)}%')\n",
    "print(f'Test recall: {round(score[3]*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test score: 0.077\n",
      "Test accuracy: 87%\n",
      "Test precision: 95%\n",
      "Test recall: 81%\n"
     ]
    }
   ],
   "source": [
    "# Imbalance Classes\n",
    "score = model.evaluate(balanced_test_data, verbose=0, steps=40)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test precision: {round(score[2]*100)}%')\n",
    "print(f'Test recall: {round(score[3]*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very interesting result. After training first on imbalanced and then balanced training data, the model performs the exactly same on balanced and imbalanced test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfreeze layers\n",
    "\n",
    "# reduce learning rate\n",
    "optimizer = keras.optimizers.Adam(\n",
    "    learning_rate = .00005,\n",
    ")\n",
    "# compile\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "model.fit(\n",
    "    imbalanced_data,\n",
    "    epochs = 5,\n",
    "    steps_per_epoch = 4000,\n",
    "    verbose = 1,\n",
    ")\n",
    "\n",
    "score = model.evaluate(imbalanced_test_data, verbose=0, steps=400)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test precision: {round(score[2]*100)}%')\n",
    "print(f'Test recall: {round(score[3]*100)}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
