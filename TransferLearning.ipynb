{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local imports\n",
    "from src.transfer import replace_head, METRICS\n",
    "from src.data import player_data\n",
    "from src.util import display_progress\n",
    "\n",
    "# computation / deep learning imports\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# os / filesystem imports\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# visualization imports\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model with Pre-Trained Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282758) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-4_layer_call_and_return_conditional_losses_1283532) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_activation_2_layer_call_and_return_conditional_losses_1284374) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_4_layer_call_and_return_conditional_losses_1283891) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_activation_3_layer_call_and_return_conditional_losses_1284517) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_6_layer_call_and_return_conditional_losses_1284115) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_7_layer_call_and_return_conditional_losses_1280886) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-1_layer_call_and_return_conditional_losses_1283204) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_4_layer_call_and_return_conditional_losses_1280033) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_7_layer_call_and_return_conditional_losses_1284254) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_6_layer_call_and_return_conditional_losses_1280683) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_5_layer_call_and_return_conditional_losses_1280358) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_conv1d_5_layer_call_and_return_conditional_losses_1284003) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_DenseCell-2_layer_call_and_return_conditional_losses_1283816) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-2_layer_call_and_return_conditional_losses_1283336) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_SSBML-Base-Model_layer_call_and_return_conditional_losses_1282960) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_DenseCell-2_layer_call_and_return_conditional_losses_1283783) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-3_layer_call_and_return_conditional_losses_1283477) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_DenseCell-1_layer_call_and_return_conditional_losses_1283693) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-4_layer_call_and_return_conditional_losses_1283553) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-3_layer_call_and_return_conditional_losses_1283435) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference__wrapped_model_1279853) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-1_layer_call_and_return_conditional_losses_1283163) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_DenseCell-1_layer_call_and_return_conditional_losses_1283660) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_ConvCell-2_layer_call_and_return_conditional_losses_1283295) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_activation_2_layer_call_and_return_conditional_losses_1281183) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
      "\u001b[33mWARNING\u001b[0m: Importing a function (__inference_activation_3_layer_call_and_return_conditional_losses_1281532) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = keras.models.load_model('models/SSBML-Base-Model')\n",
    "\n",
    "# replace head\n",
    "model = replace_head(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SSBML-Transfer-Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "SSBML-Base-Model (Sequential (None, 512)               6537842   \n",
      "_________________________________________________________________\n",
      "Binary-Classifier (Sequentia (None, 1)                 83329     \n",
      "=================================================================\n",
      "Total params: 6,621,171\n",
      "Trainable params: 82,817\n",
      "Non-trainable params: 6,538,354\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blynde\tCuckDaddy  gh0st  ixwonkr  Lie0x  TCBL\n"
     ]
    }
   ],
   "source": [
    "!ls data/player"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Player Data\n",
    "\n",
    "Player Data (clips played by our chosen player) can be found in data/player/\\<player name\\>\n",
    "\n",
    "Anonymous Data (clips not played by our chosen player) is taken from the large dataset data/character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the player we want to train/test on\n",
    "player_name = 'Blynde'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Located at: \n",
      "\t- data/player/Blynde/train \n",
      "\t- data/character/train \n",
      "\n",
      "Testing Data Located at: \n",
      "\t- data/player/Blynde/test \n",
      "\t- data/character/test \n",
      "\n",
      "Player Training Data Sample size: \n",
      "\t- 4286 \n",
      "\n",
      "Player Testing Data Sample size: \n",
      "\t- 499 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set all filepath related variables\n",
    "\n",
    "player_dir = os.path.join('data/player', player_name)\n",
    "player_train_dir = os.path.join(player_dir, 'train')\n",
    "player_test_dir = os.path.join(player_dir, 'test')\n",
    "player_train_sample_size = len(os.listdir(player_train_dir))\n",
    "player_test_sample_size = len(os.listdir(player_test_dir))\n",
    "\n",
    "anonymous_dir = 'data/character'\n",
    "anonymous_train_dir = os.path.join(anonymous_dir, 'train')\n",
    "anonymous_test_dir = os.path.join(anonymous_dir, 'test')\n",
    "\n",
    "print(f'Training Data Located at: \\n\\t- {player_train_dir} \\n\\t- {anonymous_train_dir} \\n')\n",
    "print(f'Testing Data Located at: \\n\\t- {player_test_dir} \\n\\t- {anonymous_test_dir} \\n')\n",
    "print(f'Player Training Data Sample size: \\n\\t- {player_train_sample_size} \\n')\n",
    "print(f'Player Testing Data Sample size: \\n\\t- {player_test_sample_size} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Train the model on a mix of the chosen player's clips,\n",
    "and random anonymous clips from the Melee Public SLP Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustable Parameters\n",
    "# =====================\n",
    "\n",
    "DEFAULT_BATCH_SIZE = 16\n",
    "\n",
    "# Anonymous Clips / Chosen Player's Clips\n",
    "class_balance_ratio = 5\n",
    "\n",
    "# Affects batch_size and steps_per_epoch\n",
    "# Example: ratio of 2 would effectively \n",
    "#          double batch size and \n",
    "#          cut steps_per_epoch in half\n",
    "tuning_ratio = 1\n",
    "\n",
    "# =====================\n",
    "\n",
    "# Calculate number of steps per epoch for train/test loops.\n",
    "# One Epoch should iterate through our player's clips once, mixing them\n",
    "# with random anonymous clips at our given class balance ratio \n",
    "train_steps = (\n",
    "    (player_train_sample_size * (1 + class_balance_ratio))\n",
    "    // (tuning_ratio * DEFAULT_BATCH_SIZE)\n",
    ")\n",
    "    \n",
    "test_steps = (\n",
    "    (player_test_sample_size * (1 + class_balance_ratio))\n",
    "    // (tuning_ratio * DEFAULT_BATCH_SIZE)\n",
    ")\n",
    "\n",
    "# training data\n",
    "training_data = player_data(\n",
    "    player_train_dir,\n",
    "    anonymous_train_dir,\n",
    "    repeat = True,\n",
    "    batch_size = DEFAULT_BATCH_SIZE * tuning_ratio,\n",
    "    ratio = class_balance_ratio,\n",
    ")\n",
    "\n",
    "# testing data\n",
    "testing_data = player_data(\n",
    "    player_test_dir,\n",
    "    anonymous_test_dir,\n",
    "    repeat = True,\n",
    "    batch_size = DEFAULT_BATCH_SIZE * tuning_ratio,\n",
    "    ratio = class_balance_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1607/1607 [==============================] - 421s 260ms/step - loss: 0.0599 - accuracy: 0.8161 - precision: 0.4315 - recall: 0.1981 - specificity: 0.9356\n",
      "Epoch 2/15\n",
      "1607/1607 [==============================] - 419s 261ms/step - loss: 0.0306 - accuracy: 0.8654 - precision: 0.8240 - recall: 0.2441 - specificity: 0.9890\n",
      "Epoch 3/15\n",
      "1607/1607 [==============================] - 416s 259ms/step - loss: 0.0281 - accuracy: 0.8721 - precision: 0.8542 - recall: 0.3014 - specificity: 0.9888\n",
      "Epoch 4/15\n",
      "1607/1607 [==============================] - 418s 260ms/step - loss: 0.0266 - accuracy: 0.8796 - precision: 0.8707 - recall: 0.3142 - specificity: 0.9891\n",
      "Epoch 5/15\n",
      "1607/1607 [==============================] - 419s 261ms/step - loss: 0.0265 - accuracy: 0.8769 - precision: 0.8648 - recall: 0.3147 - specificity: 0.9901\n",
      "Epoch 6/15\n",
      "1607/1607 [==============================] - 420s 261ms/step - loss: 0.0254 - accuracy: 0.8838 - precision: 0.8739 - recall: 0.3428 - specificity: 0.9903\n",
      "Epoch 7/15\n",
      "1607/1607 [==============================] - 420s 261ms/step - loss: 0.0244 - accuracy: 0.8883 - precision: 0.8796 - recall: 0.3580 - specificity: 0.9905\n",
      "Epoch 8/15\n",
      "1607/1607 [==============================] - 419s 261ms/step - loss: 0.0244 - accuracy: 0.8896 - precision: 0.8881 - recall: 0.3546 - specificity: 0.9909\n",
      "Epoch 9/15\n",
      "1607/1607 [==============================] - 420s 261ms/step - loss: 0.0246 - accuracy: 0.8839 - precision: 0.8765 - recall: 0.3485 - specificity: 0.9903\n",
      "Epoch 10/15\n",
      "1607/1607 [==============================] - 418s 260ms/step - loss: 0.0241 - accuracy: 0.8907 - precision: 0.8970 - recall: 0.3882 - specificity: 0.9906\n",
      "Epoch 11/15\n",
      "1607/1607 [==============================] - 422s 262ms/step - loss: 0.0241 - accuracy: 0.8856 - precision: 0.8703 - recall: 0.3972 - specificity: 0.9876\n",
      "Epoch 12/15\n",
      "1607/1607 [==============================] - 418s 260ms/step - loss: 0.0232 - accuracy: 0.8931 - precision: 0.8885 - recall: 0.3968 - specificity: 0.9903\n",
      "Epoch 13/15\n",
      "1607/1607 [==============================] - 422s 262ms/step - loss: 0.0224 - accuracy: 0.8979 - precision: 0.8866 - recall: 0.4435 - specificity: 0.9887\n",
      "Epoch 14/15\n",
      "1607/1607 [==============================] - 417s 260ms/step - loss: 0.0221 - accuracy: 0.8984 - precision: 0.8916 - recall: 0.4141 - specificity: 0.9893\n",
      "Epoch 15/15\n",
      "1607/1607 [==============================] - 423s 263ms/step - loss: 0.0229 - accuracy: 0.8944 - precision: 0.8926 - recall: 0.4049 - specificity: 0.9905\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_data,\n",
    "    epochs = 15,\n",
    "    steps_per_epoch = train_steps,\n",
    "    verbose = 1,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustable Parameters\n",
    "# =====================\n",
    "\n",
    "DEFAULT_BATCH_SIZE = 16\n",
    "\n",
    "# Anonymous Clips / Chosen Player's Clips\n",
    "class_balance_ratio = 3\n",
    "\n",
    "# Affects batch_size and steps_per_epoch\n",
    "# Example: ratio of 2 would effectively \n",
    "#          double batch size and \n",
    "#          cut steps_per_epoch in half\n",
    "tuning_ratio = 1\n",
    "\n",
    "# =====================\n",
    "\n",
    "# Calculate number of steps per epoch for train/test loops.\n",
    "# One Epoch should iterate through our player's clips once, mixing them\n",
    "# with random anonymous clips at our given class balance ratio \n",
    "train_steps = (\n",
    "    (player_train_sample_size * (1 + class_balance_ratio))\n",
    "    // (tuning_ratio * DEFAULT_BATCH_SIZE)\n",
    ")\n",
    "    \n",
    "test_steps = (\n",
    "    (player_test_sample_size * (1 + class_balance_ratio))\n",
    "    // (tuning_ratio * DEFAULT_BATCH_SIZE)\n",
    ")\n",
    "\n",
    "# training data\n",
    "training_data = player_data(\n",
    "    player_train_dir,\n",
    "    anonymous_train_dir,\n",
    "    repeat = True,\n",
    "    batch_size = DEFAULT_BATCH_SIZE * tuning_ratio,\n",
    "    ratio = class_balance_ratio,\n",
    ")\n",
    "\n",
    "# testing data\n",
    "testing_data = player_data(\n",
    "    player_test_dir,\n",
    "    anonymous_test_dir,\n",
    "    repeat = True,\n",
    "    batch_size = DEFAULT_BATCH_SIZE * tuning_ratio,\n",
    "    ratio = class_balance_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1071/1071 [==============================] - 279s 261ms/step - loss: 0.0281 - accuracy: 0.8662 - precision: 0.9026 - recall: 0.5189 - specificity: 0.9814\n",
      "Epoch 2/5\n",
      "1071/1071 [==============================] - 279s 260ms/step - loss: 0.0279 - accuracy: 0.8688 - precision: 0.9036 - recall: 0.5262 - specificity: 0.9815\n",
      "Epoch 3/5\n",
      "1071/1071 [==============================] - 282s 263ms/step - loss: 0.0271 - accuracy: 0.8742 - precision: 0.9081 - recall: 0.5375 - specificity: 0.9825\n",
      "Epoch 4/5\n",
      "1071/1071 [==============================] - 279s 260ms/step - loss: 0.0279 - accuracy: 0.8690 - precision: 0.9025 - recall: 0.5315 - specificity: 0.9810\n",
      "Epoch 5/5\n",
      "1071/1071 [==============================] - 277s 259ms/step - loss: 0.0274 - accuracy: 0.8714 - precision: 0.9006 - recall: 0.5425 - specificity: 0.9802\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_data,\n",
    "    epochs = 5,\n",
    "    steps_per_epoch = train_steps,\n",
    "    verbose = 1,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustable Parameters\n",
    "# =====================\n",
    "\n",
    "DEFAULT_BATCH_SIZE = 16\n",
    "\n",
    "# Anonymous Clips / Chosen Player's Clips\n",
    "class_balance_ratio = 2\n",
    "\n",
    "# Affects batch_size and steps_per_epoch\n",
    "# Example: ratio of 2 would effectively \n",
    "#          double batch size and \n",
    "#          cut steps_per_epoch in half\n",
    "tuning_ratio = 1\n",
    "\n",
    "# =====================\n",
    "\n",
    "# Calculate number of steps per epoch for train/test loops.\n",
    "# One Epoch should iterate through our player's clips once, mixing them\n",
    "# with random anonymous clips at our given class balance ratio \n",
    "train_steps = (\n",
    "    (player_train_sample_size * (1 + class_balance_ratio))\n",
    "    // (tuning_ratio * DEFAULT_BATCH_SIZE)\n",
    ")\n",
    "    \n",
    "test_steps = (\n",
    "    (player_test_sample_size * (1 + class_balance_ratio))\n",
    "    // (tuning_ratio * DEFAULT_BATCH_SIZE)\n",
    ")\n",
    "\n",
    "# training data\n",
    "training_data = player_data(\n",
    "    player_train_dir,\n",
    "    anonymous_train_dir,\n",
    "    repeat = True,\n",
    "    batch_size = DEFAULT_BATCH_SIZE * tuning_ratio,\n",
    "    ratio = class_balance_ratio,\n",
    ")\n",
    "\n",
    "# testing data\n",
    "testing_data = player_data(\n",
    "    player_test_dir,\n",
    "    anonymous_test_dir,\n",
    "    repeat = True,\n",
    "    batch_size = DEFAULT_BATCH_SIZE * tuning_ratio,\n",
    "    ratio = class_balance_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "803/803 [==============================] - 210s 261ms/step - loss: 0.0314 - accuracy: 0.8517 - precision: 0.9121 - recall: 0.6071 - specificity: 0.9714\n",
      "Epoch 2/5\n",
      "803/803 [==============================] - 210s 261ms/step - loss: 0.0298 - accuracy: 0.8617 - precision: 0.9171 - recall: 0.6333 - specificity: 0.9723\n",
      "Epoch 3/5\n",
      "803/803 [==============================] - 210s 261ms/step - loss: 0.0303 - accuracy: 0.8589 - precision: 0.9118 - recall: 0.6295 - specificity: 0.9704\n",
      "Epoch 4/5\n",
      "803/803 [==============================] - 209s 260ms/step - loss: 0.0305 - accuracy: 0.8583 - precision: 0.9095 - recall: 0.6405 - specificity: 0.9679\n",
      "Epoch 5/5\n",
      "803/803 [==============================] - 212s 265ms/step - loss: 0.0300 - accuracy: 0.8587 - precision: 0.9082 - recall: 0.6375 - specificity: 0.9681\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_data,\n",
    "    epochs = 5,\n",
    "    steps_per_epoch = train_steps,\n",
    "    verbose = 1,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjustable Parameters\n",
    "# =====================\n",
    "\n",
    "DEFAULT_BATCH_SIZE = 16\n",
    "\n",
    "# Anonymous Clips / Chosen Player's Clips\n",
    "class_balance_ratio = 1\n",
    "\n",
    "# Affects batch_size and steps_per_epoch\n",
    "# Example: ratio of 2 would effectively \n",
    "#          double batch size and \n",
    "#          cut steps_per_epoch in half\n",
    "tuning_ratio = 4\n",
    "\n",
    "# =====================\n",
    "\n",
    "# Calculate number of steps per epoch for train/test loops.\n",
    "# One Epoch should iterate through our player's clips once, mixing them\n",
    "# with random anonymous clips at our given class balance ratio \n",
    "train_steps = (\n",
    "    (player_train_sample_size * (1 + class_balance_ratio))\n",
    "    // (tuning_ratio * DEFAULT_BATCH_SIZE)\n",
    ")\n",
    "    \n",
    "test_steps = (\n",
    "    (player_test_sample_size * (1 + class_balance_ratio))\n",
    "    // (tuning_ratio * DEFAULT_BATCH_SIZE)\n",
    ")\n",
    "\n",
    "# training data\n",
    "training_data = player_data(\n",
    "    player_train_dir,\n",
    "    anonymous_train_dir,\n",
    "    repeat = True,\n",
    "    batch_size = DEFAULT_BATCH_SIZE * tuning_ratio,\n",
    "    ratio = class_balance_ratio,\n",
    ")\n",
    "\n",
    "# testing data\n",
    "testing_data = player_data(\n",
    "    player_test_dir,\n",
    "    anonymous_test_dir,\n",
    "    repeat = True,\n",
    "    batch_size = DEFAULT_BATCH_SIZE * tuning_ratio,\n",
    "    ratio = class_balance_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 93s 700ms/step - loss: 0.0308 - accuracy: 0.8600 - precision: 0.9387 - recall: 0.7723 - specificity: 0.9489\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    training_data,\n",
    "    epochs = 1,\n",
    "    steps_per_epoch = train_steps,\n",
    "    verbose = 1,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "Test the model on one pass of the given player's clips, \n",
    "at the given class balance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 13s 205ms/step - loss: 0.0292 - accuracy: 0.8919 - precision: 0.9196 - recall: 0.8545 - specificity: 0.9279\n",
      "\n",
      "Test score: 0.029\n",
      "- accuracy: 89%\n",
      "- precision: 92%\n",
      "- recall: 85%\n",
      "- specificity: 93%\n"
     ]
    }
   ],
   "source": [
    "# Adjustable Parameters\n",
    "# =====================\n",
    "\n",
    "DEFAULT_BATCH_SIZE = 16\n",
    "\n",
    "# Ratio of Anonymous clips : Chosen Player's clips\n",
    "class_balance_ratio = 1\n",
    "\n",
    "# =====================\n",
    "\n",
    "data_test_one_round = player_data(\n",
    "    player_test_dir,\n",
    "    anonymous_test_dir,\n",
    "    batch_size = DEFAULT_BATCH_SIZE,\n",
    "    repeat = False,\n",
    "    ratio = class_balance_ratio,\n",
    ")\n",
    "\n",
    "score = model.evaluate(data_test_one_round, verbose=1)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'- accuracy: {round(score[1]*100)}%')\n",
    "print(f'- precision: {round(score[2]*100)}%')\n",
    "print(f'- recall: {round(score[3]*100)}%')\n",
    "print(f'- specificity: {round(score[4]*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[####################] 499 of 499 - 100.0% \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detected</th>\n",
       "      <th>not detected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>present</th>\n",
       "      <td>0.391</td>\n",
       "      <td>0.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not present</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             detected  not detected\n",
       "present         0.391         0.068\n",
       "not present     0.041         0.500"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjustable Parameters\n",
    "# =====================\n",
    "\n",
    "DEFAULT_BATCH_SIZE = 16\n",
    "\n",
    "# Ratio of Anonymous clips : Chosen Player's clips\n",
    "class_balance_ratio = 1\n",
    "\n",
    "# =====================\n",
    "\n",
    "# define data generation\n",
    "data_conf = player_data(\n",
    "    player_test_dir,\n",
    "    anonymous_test_dir,\n",
    "    batch_size = DEFAULT_BATCH_SIZE,\n",
    "    ratio = class_balance_ratio,\n",
    ")\n",
    "\n",
    "# predict over test data\n",
    "batch_preds = []\n",
    "batch_labels = []\n",
    "i = 0\n",
    "N = player_test_sample_size\n",
    "for xi, yi in data_conf:\n",
    "    batch_preds.append(model.predict(xi).round().astype(int))\n",
    "    batch_labels.append(yi.astype(int))\n",
    "    \n",
    "    # progess bar\n",
    "    i = int(i + np.sum(yi))\n",
    "    display_progress(i, N)\n",
    "display_progress(N, N)\n",
    "print('\\n')\n",
    "\n",
    "pred = np.concatenate(batch_preds)\n",
    "labels = np.concatenate(batch_labels)\n",
    "\n",
    "# create confusion matrix\n",
    "# reverse so true positive is top left, true negative is bottom right\n",
    "conf_matrix = confusion_matrix(labels, pred, normalize='all')[::-1, ::-1] \n",
    "conf_matrix = np.around(conf_matrix, 3)\n",
    "conf_df = pd.DataFrame(\n",
    "    conf_matrix, \n",
    "    index = ['present', 'not present'], \n",
    "    columns = ['detected', 'not detected']\n",
    ")\n",
    "\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
