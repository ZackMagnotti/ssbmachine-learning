{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.generator import data_generator, clip_generator, label_generator\n",
    "from src.data import data_generator\n",
    "from src.util import characters, id_from_char, char_from_id\n",
    "from src.export import display_progress\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for character in characters:\n",
    "    print(character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Model\n",
    "\n",
    "Source code for model creation is in src/models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial_schedule = keras.optimizers.schedules.PolynomialDecay(\n",
    "#     initial_learning_rate = .1,\n",
    "#     end_learning_rate = .0001,\n",
    "#     decay_steps=100000,\n",
    "#     power=.5)\n",
    "\n",
    "# lr_schedule = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "#     boundaries = [ 10000, 20000 ],\n",
    "#     values     = [.001, .0005, .0001 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import Adam, Nadam\n",
    "# adam = Adam(learning_rate=.0001)\n",
    "# nadam = Nadam(learning_rate=.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to make a new model\n",
    "# from src.models import custom_mk5 as Model\n",
    "# model = Model()\n",
    "\n",
    "# to load the saved model\n",
    "model = keras.models.load_model('../models/custom_mk2')\n",
    "\n",
    "# from src.models import focal_loss, top_8_accuracy\n",
    "# model.compile(loss=focal_loss,\n",
    "#               optimizer=adam,\n",
    "#               metrics=['accuracy', top_8_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_generator(input_directory='../data/character/test',\n",
    "                           batch_size = 25,\n",
    "                           num_batches = 100,\n",
    "                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(data_test, verbose=1)\n",
    "\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test test top 8 categorical accuracy: {round(score[2]*100)}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_matrix(labels_as_id, predictions_as_id):\n",
    "    conf_matrix = np.zeros((27,27))\n",
    "    for i_real, i_pred in zip(labels_as_id, predictions_as_id):\n",
    "        conf_matrix[i_real, i_pred] += 1\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 100\n",
    "data_test = data_generator(input_directory='../data/character/test',\n",
    "                           batch_size = 100,\n",
    "                           num_batches = num_batches,\n",
    "                           shuffle=True,\n",
    "                           onehot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls = {k:0 for k in range(1,27)}\n",
    "precisions = {k:0 for k in range(1,27)}\n",
    "\n",
    "batch_preds = []\n",
    "batch_labels = []\n",
    "i = 0\n",
    "\n",
    "for xi, yi in data_test:\n",
    "    batch_preds.append(np.argmax(model.predict(xi), axis=1))\n",
    "    batch_labels.append(yi)\n",
    "    \n",
    "    i+=1\n",
    "    display_progress(i, num_batches)\n",
    "display_progress(num_batches, num_batches)\n",
    "    \n",
    "pred = np.concatenate(batch_preds)\n",
    "labels = np.concatenate(batch_labels)\n",
    "\n",
    "conf_matrix = get_conf_matrix(labels, pred)\n",
    "conf_df = pd.DataFrame(conf_matrix[1:,1:], index=characters, columns=characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sn.heatmap(conf_df, annot=False, mask=conf_df <= 0, cmap='viridis')\n",
    "fig, ax = plt.subplots(figsize=(13,10))\n",
    "sn.heatmap(np.log(1 + conf_df), annot=False, ax=ax, square=False)\n",
    "fig.savefig('../images/confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data generation\n",
    "data_train = data_generator(input_directory='../data/character/train',\n",
    "                            batch_size = 32,\n",
    "                            shuffle=True,\n",
    "                            repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "model.fit(data_train,\n",
    "          epochs=10,\n",
    "          steps_per_epoch=1000,\n",
    "          verbose=1)\n",
    "\n",
    "score = model.evaluate(data_train, steps=50, verbose=0)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test test top 8 accuracy: {round(score[2]*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data generation\n",
    "data_train = data_generator(input_directory='../data/character/train',\n",
    "                            batch_size = 64,\n",
    "                            shuffle=True,\n",
    "                            repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "model.fit(data_train,\n",
    "          epochs=10,\n",
    "          steps_per_epoch=500,\n",
    "          verbose=1)\n",
    "\n",
    "score = model.evaluate(data_train, steps=50, verbose=0)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test test top 8 accuracy: {round(score[2]*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data generation\n",
    "data_train = data_generator(input_directory='../data/character/train',\n",
    "                            batch_size = 64,\n",
    "                            shuffle=True,\n",
    "                            repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "model.fit(data_train,\n",
    "          epochs=5,\n",
    "          steps_per_epoch=500,\n",
    "          verbose=1)\n",
    "\n",
    "score = model.evaluate(data_train, steps=50, verbose=0)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test test top 8 accuracy: {round(score[2]*100)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Change learning rate to `.0001`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.optimizers import Adam, Nadam\n",
    "# adam = Adam(learning_rate=.0001)\n",
    "## nadam = Nadam(learning_rate=.0001)\n",
    "\n",
    "# from src.models import focal_loss, top_8_accuracy\n",
    "# model.compile(loss=focal_loss,\n",
    "#               optimizer=adam,\n",
    "#               metrics=['accuracy', top_8_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data generation\n",
    "data_train = data_generator(input_directory='../data/character/train',\n",
    "                            batch_size = 128,\n",
    "                            shuffle=True,\n",
    "                            repeat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "model.fit(data_train,\n",
    "          epochs=5,\n",
    "          steps_per_epoch=250,\n",
    "          verbose=1)\n",
    "\n",
    "score = model.evaluate(data_train, steps=50, verbose=0)\n",
    "print('\\nTest score:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1]*100)}%')\n",
    "print(f'Test test top 8 accuracy: {round(score[2]*100)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/custom_mk4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
